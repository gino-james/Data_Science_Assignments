{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzqfTLY4BLGX",
        "outputId": "58d92ced-7caf-4e6c-9468-f8694a5eef38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\n",
            "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "This will raise in a future version.\n",
            "\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import lightgbm as lgb\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler# Load datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load datasets\n",
        "try:\n",
        "    df_train = pd.read_csv('Titanic_train.csv')\n",
        "    df_test = pd.read_csv('Titanic_test.csv')\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: Could not find the datasets. Please ensure the file paths are correct.\")\n",
        "    exit()"
      ],
      "metadata": {
        "id": "gAsVfmsABN8c"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values\n",
        "print(\"Missing values in training data:\")\n",
        "print(df_train.isnull().sum())\n",
        "print(\"Missing values in testing data:\")\n",
        "print(df_test.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3oLGZbE2DMcK",
        "outputId": "0b59916d-e065-4328-89f7-899608ff47a5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values in training data:\n",
            "PassengerId      0\n",
            "Survived         0\n",
            "Pclass           0\n",
            "Name             0\n",
            "Sex              0\n",
            "Age            177\n",
            "SibSp            0\n",
            "Parch            0\n",
            "Ticket           0\n",
            "Fare             0\n",
            "Cabin          687\n",
            "Embarked         2\n",
            "dtype: int64\n",
            "Missing values in testing data:\n",
            "PassengerId      0\n",
            "Pclass           0\n",
            "Name             0\n",
            "Sex              0\n",
            "Age             86\n",
            "SibSp            0\n",
            "Parch            0\n",
            "Ticket           0\n",
            "Fare             1\n",
            "Cabin          327\n",
            "Embarked         0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Impute missing values\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "df_train['Age'] = imputer.fit_transform(df_train[['Age']])\n",
        "df_test['Age'] = imputer.transform(df_test[['Age']])"
      ],
      "metadata": {
        "id": "fG4AohzCDPIE"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['Embarked'].fillna(df_train['Embarked'].mode()[0], inplace=True)\n",
        "df_test['Fare'].fillna(df_test['Fare'].median(), inplace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5xexlFwDSP-",
        "outputId": "a294c27b-dd50-4c35-af82-d04ea3e33e77"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-a35d9c4a1529>:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_train['Embarked'].fillna(df_train['Embarked'].mode()[0], inplace=True)\n",
            "<ipython-input-5-a35d9c4a1529>:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_test['Fare'].fillna(df_test['Fare'].median(), inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.drop(columns=['Cabin'], inplace=True)\n",
        "df_test.drop(columns=['Cabin'], inplace=True)"
      ],
      "metadata": {
        "id": "VW5m1pZyDVV2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode categorical variables\n",
        "df_train = pd.get_dummies(df_train, columns=['Sex', 'Embarked'], drop_first=True)\n",
        "df_test = pd.get_dummies(df_test, columns=['Sex', 'Embarked'], drop_first=True)"
      ],
      "metadata": {
        "id": "LuwXl0yLDX-d"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure the same columns in both datasets\n",
        "for col in df_train.columns:\n",
        "    if col not in df_test.columns:\n",
        "        df_test[col] = 0\n",
        "\n",
        "for col in df_test.columns:\n",
        "    if col not in df_train.columns:\n",
        "        df_train[col] = 0"
      ],
      "metadata": {
        "id": "w0Od4Iy_Dakn"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reorder the columns to match exactly\n",
        "df_train = df_train[df_test.columns]"
      ],
      "metadata": {
        "id": "PHGDWL1EDdod"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop columns that are not useful for the model\n",
        "df_train.drop(columns=['Name', 'Ticket'], inplace=True)\n",
        "df_test.drop(columns=['Name', 'Ticket'], inplace=True)"
      ],
      "metadata": {
        "id": "1yWzioK8Dgjw"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "features_to_scale = ['Age', 'Fare']\n",
        "df_train[features_to_scale] = scaler.fit_transform(df_train[features_to_scale])\n",
        "df_test[features_to_scale] = scaler.transform(df_test[features_to_scale])"
      ],
      "metadata": {
        "id": "J8rLiW_8Djyt"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate the target variable from the features\n",
        "try:\n",
        "    X_train = df_train.drop(columns=['Survived'])\n",
        "    y_train = df_train['Survived']\n",
        "\n",
        "    X_test = df_test.drop(columns=['Survived'])\n",
        "    y_test = df_test['Survived']\n",
        "except KeyError as e:\n",
        "    print(f\"Error: {e} not found in the dataset columns.\")\n",
        "    exit()"
      ],
      "metadata": {
        "id": "L7IhfvJcDnPM"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build predictive models\n",
        "lgb_model = lgb.LGBMClassifier()\n",
        "lgb_model.fit(X_train, y_train)\n",
        "y_pred_lgb = lgb_model.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ao17-2hiDqLa",
        "outputId": "c757e9ad-25f0-4640-80e4-d9b1de329505"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 342, number of negative: 549\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000511 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 478\n",
            "[LightGBM] [Info] Number of data points in the train set: 891, number of used features: 9\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383838 -> initscore=-0.473288\n",
            "[LightGBM] [Info] Start training from score -0.473288\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_model = XGBClassifier()\n",
        "xgb_model.fit(X_train, y_train)\n",
        "y_pred_xgb = xgb_model.predict(X_test)"
      ],
      "metadata": {
        "id": "5wyK8KJTDtKk"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the models\n",
        "def evaluate_model(y_test, y_pred):\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    return accuracy, precision, recall, f1"
      ],
      "metadata": {
        "id": "N1ox5OM9Dvmi"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lgb_results = evaluate_model(y_test, y_pred_lgb)\n",
        "xgb_results = evaluate_model(y_test, y_pred_xgb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuiqkCP0DyG4",
        "outputId": "cf5ee125-01e9-47e8-8a7b-2d8d75f5df23"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'LightGBM Results: Accuracy={lgb_results[0]}, Precision={lgb_results[1]}, Recall={lgb_results[2]}, F1-score={lgb_results[3]}')\n",
        "print(f'XGBoost Results: Accuracy={xgb_results[0]}, Precision={xgb_results[1]}, Recall={xgb_results[2]}, F1-score={xgb_results[3]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTdfjb5rD0vW",
        "outputId": "e826d682-2163-46d1-805a-60252b30048c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LightGBM Results: Accuracy=0.6626794258373205, Precision=0.0, Recall=0.0, F1-score=0.0\n",
            "XGBoost Results: Accuracy=0.6674641148325359, Precision=0.0, Recall=0.0, F1-score=0.0\n"
          ]
        }
      ]
    }
  ]
}